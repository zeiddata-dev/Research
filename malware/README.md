# Zeid Data â€“ Malware Research ğŸ˜ˆğŸ”¬

Welcome to Zeid Dataâ€™s **defensive** malware research folder. Yes, *defensive* as in: **detection engineering, incident response, and control validation** across endpoint, network, identity, cloud, and data plane telemetryâ€¦ not â€œhow to become the reason your SOC has trust issues.â€ ğŸ™ƒ

Everything here is intended to be **safe for public release**: sanitized artifacts, non sensitive indicators, and defensive reproduction where it makes sense. If youâ€™re looking for weaponized automation, youâ€™re in the wrong folder and also in the wrong life choices. ğŸ˜‡

## Organization ğŸ“

Research is organized by malware family:

`research/malware/<family>/`

Examples:

* `research/malware/qilin/`
* `research/malware/lockbit/`
* `research/malware/black-basta/`

Use the most common family name from reputable sources. If naming is disputed (because of course it is), pick one canonical folder name and document aliases in the family README like a grown-up. ğŸ¤

## Standard family module layout ğŸ§±

Minimum required (aka â€œdo not submit vibesâ€):

* `README.md`
* `references.md`
* `iocs/`
* `mitigations/`

Recommended (as applicable, because reality is messy):

* `detections/`
* `workbooks/`
* `repro/`
* `samples/` (sanitized)
* `pcaps/` (sanitized)
* `figures/`
* `field-mapping.md`
* `assumptions.md`

Suggested structure:

```
research/malware/<family>/
  README.md
  references.md
  assumptions.md
  field-mapping.md
  iocs/
    domains.csv
    ips.csv
    hashes.csv
    urls.csv
  detections/
    vendor/
    sigma/
    yara/
    suricata/
  workbooks/
    sentinel/
    splunk/
  mitigations/
    hardening.md
    verification.md
    response-notes.md
  repro/
    README.md
    scripts/
    inputs/ (sanitized)
    expected/
  samples/ (sanitized)
  pcaps/ (sanitized)
  figures/
```

## Technical write up standard (family README.md) ğŸ§ ğŸ“Œ

Each family README should be written for operational use. Not for storytelling. Not for ego. Not for â€œI saw this on Twitter.â€ ğŸ˜Œ

1. **Overview**

* family summary and primary objectives (encryption, extortion, persistence, access broker workflow)
* known aliases (if any)

2. **Threat model**

* environment assumptions (enterprise vs SMB, Windows vs Linux, domain joined vs cloud native)
* attacker objectives (credential theft, lateral movement, data theft, encryption)

3. **Kill chain and TTPs**

* initial access vectors (supported by references, not vibes)
* execution and staging patterns
* privilege escalation and credential access
* discovery and lateral movement
* exfiltration and encryption

4. **Observables by telemetry layer**

* Endpoint: process trees, modules, persistence, service/task creation, file system patterns
* Network: DNS/TLS/HTTP artifacts, egress shapes, C2 and exfil mechanics
* Identity/Cloud: non interactive auth, suspicious app activity, bulk export patterns
* Data plane: anomalous queries, staging buckets, large outbound transfers

5. **Detection guidance**

* behavior first detection logic (because static IOCs age like milk ğŸ¥›)
* correlation strategy (join keys, time windows, skew tolerance)
* tuning guidance and common false positives (yes, you have to do this part ğŸ˜µâ€ğŸ’«)

6. **Indicators (IOC strategy)**

* IOC sets with provenance and time bounds
* emphasize behavioral discriminators over static indicators where possible

7. **Mitigations and validation**

* preventive controls (hardening, segmentation, least privilege)
* detective controls (logging requirements, alerting)
* verification steps (confirm controls are active and effective, not â€œenabled in theoryâ€ âœ…)

8. **Response notes**

* triage order (what to check first so youâ€™re not chasing ghosts ğŸ‘»)
* containment options (identity lock, isolate hosts, block egress)
* evidence capture guidance (what to preserve so you can actually learn something)

9. **Limitations**

* telemetry gaps and blind spots
* expected evasion strategies
* where indicators may be unreliable (because attackers read docs too ğŸ˜¬)

10. **References**

* link to `references.md`

## IOC standards ğŸ§¾ğŸ§¯

Indicators live under `iocs/` and **must include provenance** (because â€œtrust me broâ€ is not a source).

Recommended files:

* `iocs/domains.csv`
* `iocs/ips.csv`
* `iocs/hashes.csv`
* `iocs/urls.csv`

Required columns:

* `indicator`
* `type` (domain|ip|sha256|url|registry|user-agent|cert)
* `first_seen`
* `last_seen`
* `source`
* `confidence` (low|medium|high)
* `context`
* `tags`

Do **not** commit customer identifiers, internal domains, or private infrastructure data. Use public attributed infrastructure only, and document the source. If you leak a tenant ID â€œby accident,â€ itâ€™s not an accident, itâ€™s a rÃ©sumÃ© generating event. ğŸ™‚ğŸª¦

## Evidence and safety requirements ğŸ§¼ğŸ”’

This folder is defensive and responsible:

* sanitize all artifacts (no secrets, no usernames/emails/tenant IDs) ğŸ˜‡
* avoid publishing weaponized exploit automation (go write a novel instead)
* repro harnesses must be defensive oriented (validation + telemetry testing)
* document redactions and limitations clearly (future you will thank you) ğŸ™

## Contributing checklist âœ…ğŸ˜¤

Before adding or updating a malware family:

* [ ] correct path: `research/malware/<family>/`
* [ ] `README.md` follows the technical structure
* [ ] `references.md` includes primary sources
* [ ] `iocs/` present with required columns and provenance
* [ ] mitigations include verification steps
* [ ] detections declare telemetry prerequisites and tuning 
* [ ] artifacts are sanitized and safe for public release
