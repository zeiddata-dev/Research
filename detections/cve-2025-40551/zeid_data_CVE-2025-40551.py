#!/usr/bin/env python3
"""zeid_data_CVE-2025-40551 — SolarWinds Web Help Desk exploitation detector (defensive-only)

Hunts for exploitation attempts consistent with CVE-2025-40551 and related WHD/AjaxProxy bypass patterns by scanning:
  - Web access logs (IIS W3C or common/combined)
  - Optional WHD app logs (plain text)
  - Optional process telemetry exported to JSON (EDR/Sysmon export)

This tool does NOT exploit anything and does NOT change any systems.
"""

from __future__ import annotations

import argparse
import json
import re
import sys
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# Web request patterns (defensive hunting signatures)
SUSPICIOUS_PATH_SUBSTRINGS = [
    "/helpdesk/WebObjects/Helpdesk.woa/wo/",
    "/helpdesk/WebObjects/Helpdesk.woa/ajax/",
]
SUSPICIOUS_QUERY_SUBSTRINGS = [
    "badparam=/ajax/",
    "wopage=LoginPref",
]
SUSPICIOUS_PAYLOAD_MARKERS = [
    "JSONRpcClient",
    "jndiPath",
    "ldap://",
    "javaClass",
    "JNDIConnectionPool",
]

# Post-exploitation behavioral indicators (broad heuristics)
SUSPICIOUS_PROCESS_MARKERS = [
    ("powershell", "bits"),
    ("powershell", "start-bitstransfer"),
    ("bitsadmin", ""),
    ("schtasks", "tpmprofiler"),
    ("qemu-system", ""),
    ("wab.exe", "sspicli.dll"),
    ("toolsiq.exe", ""),
]

IIS_FIELDS_RE = re.compile(r"^#Fields:\s*(.*)$", re.IGNORECASE)
COMBINED_RE = re.compile(
    r'^(?P<ip>\S+)\s+\S+\s+\S+\s+\[(?P<time>[^\]]+)\]\s+"(?P<method>\S+)\s+(?P<uri>\S+)(?:\s+\S+)?"\s+(?P<status>\d+)'
)

@dataclass
class Finding:
    rule_id: str
    severity: str
    reason: str
    source: str
    line_no: int
    raw: str
    fields: Dict[str, str]

def load_text(path: Path) -> List[str]:
    return path.read_text(encoding="utf-8", errors="replace").splitlines()

def parse_iis_w3c(lines: List[str]) -> List[Dict[str, str]]:
    fields: Optional[List[str]] = None
    out: List[Dict[str, str]] = []
    for ln in lines:
        if ln.startswith("#"):
            m = IIS_FIELDS_RE.match(ln)
            if m:
                fields = m.group(1).split()
            continue
        if not ln.strip():
            continue
        if not fields:
            return []
        parts = ln.strip().split()
        if len(parts) < len(fields):
            continue
        out.append({fields[i]: parts[i] for i in range(len(fields))})
    return out

def normalize_uri(stem: str, query: str) -> str:
    if query and query != "-":
        return f"{stem}?{query}"
    return stem

def scan_uri(uri: str) -> List[Tuple[str, str, str]]:
    u = uri.lower()
    hits: List[Tuple[str, str, str]] = []
    if any(p.lower() in u for p in SUSPICIOUS_PATH_SUBSTRINGS) and all(q.lower() in u for q in SUSPICIOUS_QUERY_SUBSTRINGS):
        hits.append(("WHD_LOGINPREF_AJAXPROXY_PRIMER", "high", "LoginPref + badparam=/ajax/ pattern (AjaxProxy priming indicator)"))
    if "/helpdesk/webobjects/helpdesk.woa/wo/" in u and "badparam=/ajax/" in u:
        hits.append(("WHD_AJAX_TO_WO_BYPASS", "high", "'/wo/' path with badparam=/ajax/ (ajax→wo sanitization bypass indicator)"))
    if any(m.lower() in u for m in SUSPICIOUS_PAYLOAD_MARKERS):
        hits.append(("WHD_SUSPICIOUS_PAYLOAD_MARKERS", "high", "URI contains JSON-RPC / JNDI payload markers"))
    # lower-confidence: /ajax/ string in params without wopage
    if "badparam=" in u and "/ajax/" in u and "wopage=" not in u:
        hits.append(("WHD_AJAX_STRING_IN_PARAMS", "medium", "URI parameters contain '/ajax/' (potential bypass attempt)"))
    return hits

def scan_app_log_line(line: str) -> Optional[Tuple[str, str, str]]:
    l = line.lower()
    if "whitelisted payload with matched keyword" in l:
        return ("WHD_WHITELIST_BYPASS_LOG", "high", "App log indicates 'whitelisted payload' processing")
    if "ajaxproxy" in l and ("jsonrpc" in l or "json-rpc" in l):
        return ("WHD_AJAXPROXY_JSONRPC_LOG", "medium", "App log references AjaxProxy/JSON-RPC activity")
    return None

def scan_process_event(evt: Dict[str, object]) -> List[Tuple[str, str, str]]:
    hits: List[Tuple[str, str, str]] = []
    image = str(evt.get("Image") or evt.get("image") or evt.get("process") or "").lower()
    cmd = str(evt.get("CommandLine") or evt.get("commandLine") or evt.get("cmd") or "").lower()
    combined = f"{image} {cmd}"
    for proc, marker in SUSPICIOUS_PROCESS_MARKERS:
        if proc in combined and (marker == "" or marker.lower() in combined):
            sev = "high" if proc in ("schtasks", "qemu-system") else "medium"
            hits.append(("WHD_POSTEXP_BEHAVIOR", sev, f"Process pattern match: {proc} {marker}".strip()))
    return hits

def main(argv: Optional[List[str]] = None) -> int:
    ap = argparse.ArgumentParser(
        prog="zeid_data_CVE-2025-40551",
        description="Detect SolarWinds Web Help Desk exploitation attempts for CVE-2025-40551 (defensive-only)."
    )
    ap.add_argument("--web-log", action="append", default=[], help="Web access log file. Repeatable.")
    ap.add_argument("--app-log", action="append", default=[], help="WHD application log file. Repeatable.")
    ap.add_argument("--proc-json", action="append", default=[], help="JSON file with process events (list or {events:[...]}). Repeatable.")
    ap.add_argument("--out", default="", help="Write JSON findings to this path (default: stdout).")
    args = ap.parse_args(argv)

    findings: List[Finding] = []

    # Web logs
    for lp in args.web_log:
        pth = Path(lp)
        if not pth.exists():
            print(f"[!] Missing web log: {pth}", file=sys.stderr)
            continue
        lines = load_text(pth)
        w3c = parse_iis_w3c(lines)
        if w3c:
            for idx, rec in enumerate(w3c, start=1):
                stem = rec.get("cs-uri-stem", "")
                query = rec.get("cs-uri-query", "")
                uri = normalize_uri(stem, query)
                for rule_id, sev, reason in scan_uri(uri):
                    fields = {
                        "c-ip": rec.get("c-ip", ""),
                        "cs-method": rec.get("cs-method", ""),
                        "uri": uri,
                        "sc-status": rec.get("sc-status", ""),
                        "time": f"{rec.get('date','')} {rec.get('time','')}".strip(),
                    }
                    findings.append(Finding(rule_id, sev, reason, source=str(pth), line_no=idx, raw=" ".join(lines[idx-1:idx])[:5000], fields=fields))
        else:
            for idx, line in enumerate(lines, start=1):
                m = COMBINED_RE.match(line)
                if m:
                    uri = m.group("uri")
                    for rule_id, sev, reason in scan_uri(uri):
                        fields = {"c-ip": m.group("ip"), "cs-method": m.group("method"), "uri": uri, "sc-status": m.group("status"), "time": m.group("time")}
                        findings.append(Finding(rule_id, sev, reason, source=str(pth), line_no=idx, raw=line[:5000], fields=fields))
                else:
                    for rule_id, sev, reason in scan_uri(line):
                        findings.append(Finding(rule_id, sev, reason, source=str(pth), line_no=idx, raw=line[:5000], fields={"uri_or_line": line[:2000]}))

    # App logs
    for lp in args.app_log:
        pth = Path(lp)
        if not pth.exists():
            print(f"[!] Missing app log: {pth}", file=sys.stderr)
            continue
        for idx, line in enumerate(load_text(pth), start=1):
            hit = scan_app_log_line(line)
            if hit:
                rule_id, sev, reason = hit
                findings.append(Finding(rule_id, sev, reason, source=str(pth), line_no=idx, raw=line[:5000], fields={}))

    # Process telemetry
    for jp in args.proc_json:
        pth = Path(jp)
        if not pth.exists():
            print(f"[!] Missing proc JSON: {pth}", file=sys.stderr)
            continue
        try:
            data = json.loads(pth.read_text(encoding="utf-8", errors="replace"))
        except Exception as e:
            print(f"[!] Failed to parse JSON: {pth} ({e})", file=sys.stderr)
            continue
        events = data.get("events") if isinstance(data, dict) else data
        if not isinstance(events, list):
            continue
        for idx, evt in enumerate(events, start=1):
            if not isinstance(evt, dict):
                continue
            for rule_id, sev, reason in scan_process_event(evt):
                fields = {k: str(evt.get(k, "")) for k in list(evt.keys())[:30]}
                findings.append(Finding(rule_id, sev, reason, source=str(pth), line_no=idx, raw=json.dumps(evt)[:5000], fields=fields))

    payload = {
        "tool": "zeid_data_CVE-2025-40551",
        "finding_count": len(findings),
        "findings": [asdict(f) for f in findings],
        "notes": {
            "web_signatures": {"paths": SUSPICIOUS_PATH_SUBSTRINGS, "queries": SUSPICIOUS_QUERY_SUBSTRINGS, "payload_markers": SUSPICIOUS_PAYLOAD_MARKERS},
            "process_hunting": "Optional: provide JSON-exported process telemetry to catch common follow-on behaviors.",
        },
    }

    out_json = json.dumps(payload, indent=2, sort_keys=False)
    if args.out:
        Path(args.out).write_text(out_json, encoding="utf-8")
        print(f"[+] Wrote findings JSON: {args.out}")
    else:
        print(out_json)

    print(f"[summary] Findings={len(findings)}", file=sys.stderr)
    return 0

if __name__ == "__main__":
    raise SystemExit(main())
